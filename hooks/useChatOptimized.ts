import { useState, useCallback, useRef, useEffect } from 'react'
import { Message } from '@/lib/types'
import { generateId } from '@/lib/utils'

interface ChatOptions {
  onNewMessage?: (message: string) => void
  onError?: (error: string) => void
  timeout?: number
}

export function useChatOptimized() {
  const [isLoading, setIsLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const abortControllerRef = useRef<AbortController | null>(null)
  
  // ã€Ultra Thinkã€‘: Ensure isLoading is reset on mount to prevent stale state
  useEffect(() => {
    console.log('ğŸ”„ [HOOK-DEBUG] useChatOptimized mounted, resetting isLoading')
    setIsLoading(false)
    return () => {
      console.log('ğŸ”„ [HOOK-DEBUG] useChatOptimized unmounting, cleaning up')
      if (abortControllerRef.current) {
        abortControllerRef.current.abort()
      }
    }
  }, [])

  // Cancel ongoing request
  const cancelRequest = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
      abortControllerRef.current = null
      setIsLoading(false)
    }
  }, [])

  const sendMessage = useCallback(async (
    content: string,
    messages: Message[],
    phase: string,
    options?: ChatOptions
  ): Promise<string | null> => {
    console.log('ğŸš€ [FETCH-DEBUG] === sendMessage called ===')
    console.log('ğŸš€ [FETCH-DEBUG] isLoading state:', isLoading)
    console.log('ğŸš€ [FETCH-DEBUG] AbortController exists:', !!abortControllerRef.current)
    
    // Prevent multiple simultaneous requests with better error recovery
    if (isLoading) {
      console.warn('âš ï¸ [FETCH-DEBUG] Request already in progress')
      console.warn('âš ï¸ [FETCH-DEBUG] Current loading state:', isLoading)
      console.warn('âš ï¸ [FETCH-DEBUG] AbortController exists:', !!abortControllerRef.current)
      
      // ã€Ultra Thinkã€‘: Force cleanup if stuck in loading state for too long
      if (abortControllerRef.current) {
        console.warn('âš ï¸ [FETCH-DEBUG] Forcing cleanup of stuck request')
        abortControllerRef.current.abort()
        abortControllerRef.current = null
        setIsLoading(false)
        // Continue with new request after cleanup
      } else {
        // No controller but still loading - reset state
        console.warn('âš ï¸ [FETCH-DEBUG] No controller but loading=true, resetting state')
        setIsLoading(false)
        // Continue with new request
      }
    }
    
    console.log('ğŸš€ [FETCH-DEBUG] Starting new sendMessage request')
    console.log('ğŸš€ [FETCH-DEBUG] Content:', content)
    console.log('ğŸš€ [FETCH-DEBUG] Phase:', phase)

    setIsLoading(true)
    setError(null)

    // Create new AbortController for this request
    const controller = new AbortController()
    abortControllerRef.current = controller

    // Use a more generous timeout - 120 seconds for OpenAI responses
    const timeoutMs = options?.timeout || 120000
    const timeoutId = setTimeout(() => {
      console.error('[useChatOptimized] Request timed out after', timeoutMs, 'ms')
      console.error('[useChatOptimized] Aborting request due to timeout')
      // Mark this as a timeout before aborting
      controller.abort('timeout')
    }, timeoutMs)

    try {
      console.log('ğŸš€ [FETCH-DEBUG] Starting fetch to /api/chat')
      console.log('ğŸš€ [FETCH-DEBUG] Phase:', phase)
      console.log('ğŸš€ [FETCH-DEBUG] Message content:', content)
      console.log('ğŸš€ [FETCH-DEBUG] Messages count:', messages.length)
      
      // ã€Ultra Thinkã€‘: Ensure JSON serialization integrity for reliable conversation flow
      const requestBody = {
        message: content,
        messages: messages.map(m => ({
          role: m.role,
          content: m.content
        })),
        phase,
      }
      
      // Validate request body structure before serialization
      console.log('ğŸš€ [FETCH-DEBUG] Pre-serialization validation:')
      console.log('ğŸš€ [FETCH-DEBUG] - Content type:', typeof content)
      console.log('ğŸš€ [FETCH-DEBUG] - Content length:', content?.length || 0)
      console.log('ğŸš€ [FETCH-DEBUG] - Messages count:', messages?.length || 0)
      console.log('ğŸš€ [FETCH-DEBUG] - Phase:', phase)
      console.log('ğŸš€ [FETCH-DEBUG] - Request body structure:', requestBody)
      
      // Safe JSON serialization with error handling
      let serializedBody: string
      try {
        serializedBody = JSON.stringify(requestBody)
        console.log('ğŸš€ [FETCH-DEBUG] JSON serialization successful')
        console.log('ğŸš€ [FETCH-DEBUG] Serialized length:', serializedBody.length)
        console.log('ğŸš€ [FETCH-DEBUG] Serialized preview:', serializedBody.substring(0, 200) + '...')
      } catch (serializationError) {
        console.error('âŒ [FETCH-DEBUG] JSON serialization failed:', serializationError)
        throw new Error(`Failed to serialize request body: ${serializationError}`)
      }
      
      console.log('ğŸš€ [FETCH-DEBUG] Starting fetch request to /api/chat')
      console.log('ğŸš€ [FETCH-DEBUG] - Method: POST')
      console.log('ğŸš€ [FETCH-DEBUG] - Content-Type: application/json')
      console.log('ğŸš€ [FETCH-DEBUG] - Body length:', serializedBody.length)
      console.log('ğŸš€ [FETCH-DEBUG] - Signal provided:', !!controller.signal)
      
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: serializedBody,
        signal: controller.signal,
      })
      
      console.log('âœ… [FETCH-DEBUG] Fetch completed!')
      console.log('âœ… [FETCH-DEBUG] Response status:', response.status)
      console.log('âœ… [FETCH-DEBUG] Response ok:', response.ok)
      console.log('âœ… [FETCH-DEBUG] Response statusText:', response.statusText)
      console.log('âœ… [FETCH-DEBUG] Response headers:', Object.fromEntries(response.headers.entries()))

      // Always try to get response text for debugging
      let responseText: string
      try {
        responseText = await response.text()
        console.log('âœ… [FETCH-DEBUG] Response text length:', responseText.length)
        console.log('âœ… [FETCH-DEBUG] Response text preview:', responseText.substring(0, 200) + '...')
      } catch (textError) {
        console.error('âŒ [FETCH-DEBUG] Failed to read response text:', textError)
        responseText = ''
      }

      if (!response.ok) {
        console.error('âŒ [FETCH-DEBUG] HTTP error detected!')
        console.error('âŒ [FETCH-DEBUG] Status:', response.status)
        console.error('âŒ [FETCH-DEBUG] StatusText:', response.statusText)
        console.error('âŒ [FETCH-DEBUG] Error text:', responseText)
        throw new Error(`HTTP error! status: ${response.status}, text: ${responseText}`)
      }

      // Parse the response text as JSON
      let data: any
      try {
        data = JSON.parse(responseText)
        console.log('âœ… [FETCH-DEBUG] JSON parsed successfully')
        console.log('âœ… [FETCH-DEBUG] Data structure:', {
          hasMessage: !!data.message,
          messageLength: data.message?.length || 0,
          hasError: !!data.error,
          keys: Object.keys(data)
        })
      } catch (jsonError) {
        console.error('âŒ [FETCH-DEBUG] Failed to parse JSON:', jsonError)
        console.error('âŒ [FETCH-DEBUG] Raw response:', responseText)
        throw new Error('Invalid JSON response')
      }
      
      if (data.error) {
        console.error('âŒ [FETCH-DEBUG] API returned error:', data.error)
        throw new Error(data.error)
      }

      const aiResponse = data.message
      console.log('ğŸ‰ [RESPONSE-DEBUG] ===== OpenAI Response Analysis =====')
      console.log('ğŸ‰ [RESPONSE-DEBUG] Raw data:', data)
      console.log('ğŸ‰ [RESPONSE-DEBUG] Message content:', aiResponse)
      console.log('ğŸ‰ [RESPONSE-DEBUG] Message type:', typeof aiResponse)
      console.log('ğŸ‰ [RESPONSE-DEBUG] Message length:', aiResponse?.length || 0)
      console.log('ğŸ‰ [RESPONSE-DEBUG] Is string:', typeof aiResponse === 'string')
      console.log('ğŸ‰ [RESPONSE-DEBUG] Is truthy:', !!aiResponse)
      
      // Validate response content
      if (!aiResponse || typeof aiResponse !== 'string' || aiResponse.trim().length === 0) {
        console.error('âŒ [RESPONSE-DEBUG] Invalid or empty response detected!')
        console.error('âŒ [RESPONSE-DEBUG] aiResponse value:', aiResponse)
        console.error('âŒ [RESPONSE-DEBUG] Full data object:', JSON.stringify(data, null, 2))
        
        const errorMessage = 'OpenAIã‹ã‚‰ç„¡åŠ¹ãªå¿œç­”ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
        setError(errorMessage)
        options?.onError?.(errorMessage)
        return null
      }
      
      // Clear any previous errors since we got a successful response
      setError(null)
      
      console.log('ğŸ‰ [RESPONSE-DEBUG] Calling onNewMessage with:', aiResponse)
      console.log('ğŸ‰ [RESPONSE-DEBUG] onNewMessage function exists:', !!options?.onNewMessage)
      
      // Notify about the new message
      if (options?.onNewMessage) {
        try {
          console.log('ğŸ‰ [RESPONSE-DEBUG] About to call onNewMessage with:', aiResponse)
          console.log('ğŸ‰ [RESPONSE-DEBUG] onNewMessage function type:', typeof options.onNewMessage)
          console.log('ğŸ‰ [RESPONSE-DEBUG] onNewMessage function details:', options.onNewMessage.toString().substring(0, 200))
          
          options.onNewMessage(aiResponse)
          console.log('ğŸ‰ [RESPONSE-DEBUG] onNewMessage called successfully')
          
          // Add a small delay to let any state updates complete
          await new Promise(resolve => setTimeout(resolve, 100))
          console.log('ğŸ‰ [RESPONSE-DEBUG] Post-callback delay completed')
        } catch (callbackError) {
          console.error('âŒ [RESPONSE-DEBUG] Error in onNewMessage callback:', callbackError)
          console.error('âŒ [RESPONSE-DEBUG] Callback error stack:', callbackError instanceof Error ? callbackError.stack : 'No stack available')
        }
      } else {
        console.warn('âš ï¸ [RESPONSE-DEBUG] No onNewMessage callback provided!')
      }
      
      console.log('ğŸ‰ [RESPONSE-DEBUG] ===== Response Analysis Complete =====')
      return aiResponse
    } catch (err) {
      console.error('ğŸ’¥ [FETCH-DEBUG] Error caught in fetch operation!')
      console.error('ğŸ’¥ [FETCH-DEBUG] Error type:', typeof err)
      console.error('ğŸ’¥ [FETCH-DEBUG] Error constructor:', err?.constructor?.name)
      
      if (err instanceof Error) {
        console.error('ğŸ’¥ [FETCH-DEBUG] Error details:', {
          name: err.name,
          message: err.message,
          stack: err.stack
        })
        
        if (err.name === 'AbortError') {
          console.warn('ğŸš« [FETCH-DEBUG] AbortError detected - request was cancelled')
          console.warn('ğŸš« [FETCH-DEBUG] This might be intentional (user navigation, timeout, etc.)')
          console.warn('ğŸš« [FETCH-DEBUG] Not showing error to user since this could be normal behavior')
          
          // AbortErrorã®å ´åˆã€å¤šãã¯æ„å›³çš„ãªã‚­ãƒ£ãƒ³ã‚»ãƒ«ãªã®ã§ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ãªã„
          // ãŸã ã—ã€æ˜ç¤ºçš„ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨åˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
          if (err.message.includes('timeout') || err.message.includes('Timeout')) {
            console.error('ğŸš« [FETCH-DEBUG] Confirmed timeout error')
            const errorMessage = 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
            setError(errorMessage)
            options?.onError?.(errorMessage)
          } else {
            console.warn('ğŸš« [FETCH-DEBUG] Likely intentional abort - not showing error to user')
            // ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ãªã„ï¼ˆæ„å›³çš„ãªã‚­ãƒ£ãƒ³ã‚»ãƒ«ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
          }
          
          return null
        }
        
        console.error('âš ï¸ [FETCH-DEBUG] Non-abort error:', err.message)
        const errorMessage = err.message
        setError(errorMessage)
        options?.onError?.(errorMessage)
        return null
      }
      
      const errorMessage = 'é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'
      setError(errorMessage)
      options?.onError?.(errorMessage)
      return null
    } finally {
      console.log('ğŸ”„ [FETCH-DEBUG] Cleaning up fetch operation')
      if (timeoutId) {
        clearTimeout(timeoutId)
        console.log('ğŸ”„ [FETCH-DEBUG] Timeout cleared')
      }
      setIsLoading(false)
      abortControllerRef.current = null
      console.log('ğŸ”„ [FETCH-DEBUG] Loading state cleared, abort controller reset')
    }
  }, [isLoading, cancelRequest]) // ã€Ultra Thinkã€‘: isLoading must be in dependencies to prevent stale closure

  const generateStructuredData = useCallback(async (
    conversations: Message[],
    phase: string,
    options?: ChatOptions
  ): Promise<any> => {
    // Prevent multiple simultaneous requests
    if (isLoading) {
      console.warn('âš ï¸ [FETCH-DEBUG] Structured data request already in progress, ignoring new request')
      console.warn('âš ï¸ [FETCH-DEBUG] Current loading state:', isLoading)
      return null
    }
    
    console.log('ğŸš€ [FETCH-DEBUG] Starting generateStructuredData request')
    console.log('ğŸš€ [FETCH-DEBUG] Conversations count:', conversations.length)
    console.log('ğŸš€ [FETCH-DEBUG] Phase:', phase)

    setIsLoading(true)
    setError(null)

    // Create new AbortController for this request
    const controller = new AbortController()
    abortControllerRef.current = controller

    // Use a more generous timeout - 120 seconds for OpenAI responses
    const timeoutMs = options?.timeout || 120000
    const timeoutId = setTimeout(() => {
      console.error('[useChatOptimized] Request timed out after', timeoutMs, 'ms')
      console.error('[useChatOptimized] Aborting request due to timeout')
      // Mark this as a timeout before aborting
      controller.abort('timeout')
    }, timeoutMs)

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message: JSON.stringify(conversations),
          messages: [],
          phase,
          isStructured: true,
        }),
        signal: controller.signal,
      })

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const data = await response.json()
      
      if (data.error) {
        throw new Error(data.error)
      }

      // JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
      try {
        return JSON.parse(data.message)
      } catch {
        // JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ç”Ÿã®æ–‡å­—åˆ—ã‚’è¿”ã™
        return data.message
      }
    } catch (err) {
      if (err instanceof Error) {
        if (err.name === 'AbortError') {
          console.warn('ğŸš« [FETCH-DEBUG] AbortError in generateStructuredData - request was cancelled')
          console.warn('ğŸš« [FETCH-DEBUG] Details:', {
            name: err.name,
            message: err.message
          })
          
          // AbortErrorã®å ´åˆã€å¤šãã¯æ„å›³çš„ãªã‚­ãƒ£ãƒ³ã‚»ãƒ«ãªã®ã§ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ãªã„
          // ãŸã ã—ã€æ˜ç¤ºçš„ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨åˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
          if (err.message.includes('timeout') || err.message.includes('Timeout')) {
            console.error('ğŸš« [FETCH-DEBUG] Confirmed timeout error in structured data generation')
            const errorMessage = 'ãƒ‡ãƒ¼ã‚¿ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
            setError(errorMessage)
            options?.onError?.(errorMessage)
          } else {
            console.warn('ğŸš« [FETCH-DEBUG] Likely intentional abort in structured data - not showing error to user')
            // ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ãªã„ï¼ˆæ„å›³çš„ãªã‚­ãƒ£ãƒ³ã‚»ãƒ«ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
          }
          
          return null
        }
        
        const errorMessage = err.message
        setError(errorMessage)
        options?.onError?.(errorMessage)
        console.error('Structured data generation error:', err)
        return null
      }
      
      const errorMessage = 'ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'
      setError(errorMessage)
      options?.onError?.(errorMessage)
      return null
    } finally {
      console.log('ğŸ”„ [FETCH-DEBUG] Cleaning up fetch operation')
      if (timeoutId) {
        clearTimeout(timeoutId)
        console.log('ğŸ”„ [FETCH-DEBUG] Timeout cleared')
      }
      setIsLoading(false)
      abortControllerRef.current = null
      console.log('ğŸ”„ [FETCH-DEBUG] Loading state cleared, abort controller reset')
    }
  }, [cancelRequest])

  // Cleanup function to cancel request when component unmounts
  const cleanup = useCallback(() => {
    cancelRequest()
  }, [cancelRequest])

  return {
    sendMessage,
    generateStructuredData,
    cancelRequest,
    cleanup,
    isLoading,
    error,
    clearError: () => setError(null),
  }
}