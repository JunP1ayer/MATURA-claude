import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

interface StructureAutofillRequest {
  userInput: string
  stage?: string
}

export async function POST(request: NextRequest) {
  try {
    const { userInput, stage } = await request.json() as StructureAutofillRequest

    console.log('ğŸ” [DEBUG] å—ä¿¡ã—ãŸå…¥åŠ›:', userInput)
    console.log('ğŸ” [DEBUG] ã‚¹ãƒ†ãƒ¼ã‚¸:', stage)

    if (!userInput || userInput.trim().length === 0) {
      return NextResponse.json(
        { error: 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒå¿…è¦ã§ã™' },
        { status: 400 }
      )
    }

    let prompt = ''
    if (stage) {
      // å€‹åˆ¥ã‚¹ãƒ†ãƒ¼ã‚¸ã®æ”¯æ´
      prompt = `ã‚ãªãŸã¯æ€è€ƒæ§‹é€ åŒ–ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å…¥åŠ›å†…å®¹ã«åŸºã¥ã„ã¦ã€${stage}ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›å†…å®¹: ${userInput}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
- why: ç›®çš„ãƒ»ç†ç”±ï¼ˆãªãœã‚„ã‚‹ã®ã‹ï¼‰
- who: å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆã ã‚Œã®ãŸã‚ã‹ï¼‰
- what: æä¾›ã™ã‚‹æ©Ÿèƒ½ãƒ»ä¾¡å€¤ï¼ˆãªã«ã‚’æä¾›ã™ã‚‹ã‹ï¼‰â€»é…åˆ—å½¢å¼
- how: å®Ÿç¾æ–¹æ³•ï¼ˆã©ã†ã‚„ã£ã¦å®Ÿç¾ã™ã‚‹ã‹ï¼‰
- impact: æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœï¼ˆã©ã‚“ãªåŠ¹æœãƒ»å¤‰åŒ–ã‚’ç”Ÿã‚€ã‹ï¼‰

ç‰¹ã«${stage}ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚`
    } else {
      // å…¨ä½“æ§‹é€ åŒ–
      prompt = `ã‚ãªãŸã¯æ€è€ƒæ§‹é€ åŒ–ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’åˆ†æã—ã¦ã€Why/Who/What/How/Impactã®5ã¤ã®è¦³ç‚¹ã§æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: ${userInput}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
- why: ç›®çš„ãƒ»ç†ç”±ï¼ˆãªãœã‚„ã‚‹ã®ã‹ï¼‰
- who: å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆã ã‚Œã®ãŸã‚ã‹ï¼‰
- what: æä¾›ã™ã‚‹æ©Ÿèƒ½ãƒ»ä¾¡å€¤ï¼ˆãªã«ã‚’æä¾›ã™ã‚‹ã‹ï¼‰â€»é…åˆ—å½¢å¼ã§3-5å€‹
- how: å®Ÿç¾æ–¹æ³•ï¼ˆã©ã†ã‚„ã£ã¦å®Ÿç¾ã™ã‚‹ã‹ï¼‰
- impact: æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœï¼ˆã©ã‚“ãªåŠ¹æœãƒ»å¤‰åŒ–ã‚’ç”Ÿã‚€ã‹ï¼‰

å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚`
    }

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: prompt },
        { role: "user", content: userInput }
      ],
      temperature: 0.7,
      max_tokens: 1000,
    })

    const response = completion.choices[0]?.message?.content
    if (!response) {
      throw new Error('OpenAI APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™')
    }

    console.log('ğŸ” [DEBUG] OpenAIå¿œç­”:', response)

    // JSONãƒ‘ãƒ¼ã‚¹
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('JSONå½¢å¼ã®å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
    }

    const structure = JSON.parse(jsonMatch[0])
    console.log('ğŸ” [DEBUG] ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿æ§‹é€ :', structure)

    return NextResponse.json({
      success: true,
      data: {
        userInput,
        stage,
        structure,
        note: stage ? `${stage}ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸ` : 'å…¨ä½“æ§‹é€ ã‚’ç”Ÿæˆã—ã¾ã—ãŸ'
      }
    })

  } catch (error: any) {
    console.error('æ§‹é€ åŒ–ã‚¨ãƒ©ãƒ¼:', error)
    
    return NextResponse.json(
      { 
        error: 'æ§‹é€ åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ', 
        details: error.message 
      },
      { status: 500 }
    )
  }
}

export async function GET(request: NextRequest) {
  return NextResponse.json({
    message: 'æ§‹é€ åŒ–è‡ªå‹•å…¥åŠ›API',
    usage: {
      method: 'POST',
      body: {
        userInput: 'å¿…é ˆ - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚å†…å®¹'
      },
      example: {
        userInput: 'æ¥½ã—ã„æ—¥è¨˜ã‚¢ãƒ—ãƒªã‚’ä½œã‚ŠãŸã„'
      }
    },
    output: {
      why: 'ç›®çš„ãƒ»ç†ç”±',
      who: 'å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼',
      what: 'æä¾›ã™ã‚‹æ©Ÿèƒ½ãƒ»ä¾¡å€¤',
      how: 'å®Ÿç¾æ–¹æ³•',
      impact: 'æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ'
    }
  })
}